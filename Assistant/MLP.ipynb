{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a21aab-be63-45a3-a669-939850988f1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 🧠 EEG Classification Pipeline – Step-by-Step Guide\n",
    "\n",
    "## 🧠 Step 1: Setup and Dataset Loading\n",
    "- Set logging level for MNE to avoid cluttered output.\n",
    "- Set dataset path (`tuab_path`) pointing to TUAB `.edf` folder.\n",
    "- Load train and eval datasets from the TUAB abnormal dataset using `TUHAbnormal`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🏷 Step 2: Assign Labels (Normal = 0, Abnormal = 1)\n",
    "- Iterate over each dataset in train and eval sets.\n",
    "- Check if the path contains `\"normal\"` to assign `target = 0`, otherwise `target = 1`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🎧 Step 3: Select Common EEG Channels\n",
    "- Define a list of 21 standard EEG channels.\n",
    "- Filter each dataset to keep only those common channels.\n",
    "\n",
    "---\n",
    "\n",
    "## 💥 Step 4: Handle Artifacts in Normal Train Samples\n",
    "- Split train dataset into `train_normal` and `train_abnormal`.\n",
    "- For `train_normal`:\n",
    "  - Use `annotate_muscle_zscore()` to detect muscle artifacts.\n",
    "  - Remove those artifacts from the annotations.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧹 Step 5: Apply Preprocessing\n",
    "- Define preprocessors:\n",
    "  - Bandpass filtering (0.5–40 Hz)\n",
    "  - Rescale signal amplitude (Volts → µV)\n",
    "- Load EEG into memory for both `train_normal` and `train_abnormal`.\n",
    "- Apply preprocessing to each dataset.\n",
    "- Also preprocess `eval_dataset`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Step 6: Combine and Window the Data\n",
    "- Recombine cleaned `train_normal` and `train_abnormal`.\n",
    "- Use `create_fixed_length_windows` with:\n",
    "  - Window size: 1000 samples\n",
    "  - No overlap\n",
    "- Apply to both train and eval datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## 🏷 Step 7: Extract Labels and Pad Windows\n",
    "- Extract `target` labels from training windows.\n",
    "- Pad windows to have the same number of channels using PyTorch.\n",
    "- Convert data to tensors: `X`, `y`.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚖️ Step 8: Handle Class Imbalance\n",
    "- Flatten `X`, apply random oversampling to balance class distribution.\n",
    "- Reshape oversampled data to `[samples, channels, time]`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Step 9: Prepare Eval Dataset\n",
    "- Extract and pad windows from eval dataset similarly.\n",
    "- Save `X_eval.pt` and `y_eval.pt` for later testing.\n",
    "\n",
    "---\n",
    "\n",
    "## 📁 Step 10: Save Final Balanced Train Data\n",
    "- Save the oversampled and padded tensors: `X_resampled.pt`, `y_resampled.pt`.\n",
    "\n",
    "---\n",
    "\n",
    "## 📐 Step 11: Feature Extraction\n",
    "- Load selected feature names from text file (e.g., `\"ch_2_time_mean\"`).\n",
    "- Determine feature types to extract:\n",
    "  - Time-domain stats\n",
    "  - Power Spectral Density (PSD) bands\n",
    "  - Hjorth parameters\n",
    "  - Wavelet energies\n",
    "  - Catch22 features\n",
    "- For each window in `X_resampled`:\n",
    "  - Loop through each channel and compute only selected features.\n",
    "- Stack features into final tensor `X_feat`.\n",
    "- Save as `X_feat.pt`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧼 Step 12: Preprocess Features\n",
    "- Load `X_feat` and `y_resampled`.\n",
    "- Apply `RobustScaler` to standardize features.\n",
    "- Save the scaler as `scaler.pkl` for future inference.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔀 Step 13: Split for Training and Validation\n",
    "- Use `train_test_split` with 80/20 stratified split.\n",
    "- Create PyTorch `DataLoaders` for training and validation sets.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚖️ Step 14: Compute Class Weights\n",
    "- Compute balanced class weights for `CrossEntropyLoss`.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Step 15: Define the MLP Model\n",
    "- Define `MLPOnly` class:\n",
    "  - Layers: Input → 256 → 128 → 64 → 2 (output)\n",
    "  - Each hidden layer: BatchNorm → ReLU → Dropout\n",
    "- Initialize:\n",
    "  - Model\n",
    "  - Loss: `CrossEntropyLoss` with computed weights\n",
    "  - Optimizer: `Adam`\n",
    "  - Scheduler: `ReduceLROnPlateau`\n",
    "\n",
    "---\n",
    "\n",
    "## 🏋️ Step 16: Train the MLP\n",
    "- Loop through epochs:\n",
    "  - Train on batches with `.backward()` and `optimizer.step()`\n",
    "  - Validate after each epoch:\n",
    "    - Compute accuracy, precision, recall, F1\n",
    "    - Use scheduler to adjust learning rate\n",
    "    - Save model if it achieves best F1\n",
    "\n",
    "---\n",
    "\n",
    "## 💾 Step 17: Save the Best Model\n",
    "- Save `state_dict` of the best model as `mlp_best_model.pth`.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Final Outputs\n",
    "- `X_eval.pt`, `y_eval.pt` – evaluation data\n",
    "- `X_resampled_final.pt`, `y_resampled_final.pt` – balanced training data\n",
    "- `X_feat.pt` – handcrafted features\n",
    "- `scaler.pkl` – saved feature scaler\n",
    "- `mlp_best_model.pth` – trained MLP model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc45f0f-ec4b-41c0-95bd-936651a29754",
   "metadata": {},
   "source": [
    "## Preprocess for both MLP + Deep4Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371eb2a-7a84-4abe-b045-e3d33d3dba5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💥 Removing muscle artifacts: 100%|████████████████████████████████████████████████| 1371/1371 [33:15<00:00,  1.46s/it]\n",
      "C:\\Users\\obass\\anaconda3\\Lib\\site-packages\\braindecode\\preprocessing\\preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n",
      "⚙️ Preprocessing train_normal: 100%|███████████████████████████████████████████████| 1371/1371 [12:29<00:00,  1.83it/s]\n",
      "⚙️ Preprocessing train_abnormal: 100%|█████████████████████████████████████████████| 1346/1346 [09:09<00:00,  2.45it/s]\n",
      "⚙️ Preprocessing eval safely: 100%|██████████████████████████████████████████████████| 276/276 [01:45<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Label distribution before balancing: Counter({0: 1371, 1: 1346})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Extracting eval windows: 100%|████████████████████████████████████████████████████| 276/276 [03:11<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.datasets.tuh import TUHAbnormal\n",
    "from braindecode.preprocessing import Preprocessor, preprocess, create_fixed_length_windows\n",
    "from braindecode.datasets.base import BaseConcatDataset\n",
    "from mne.preprocessing import annotate_muscle_zscore\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress verbose MNE logs\n",
    "os.environ[\"MNE_LOGGING_LEVEL\"] = \"CRITICAL\"\n",
    "mne.set_log_level('CRITICAL')\n",
    "\n",
    "# Base path to TUAB dataset\n",
    "tuab_path = r\"C:\\Users\\obass\\Desktop\\linux_shared\\v3.0.1\\edf\"\n",
    "\n",
    "# Load training and evaluation datasets\n",
    "train_dataset = TUHAbnormal(path=os.path.join(tuab_path, \"train\"))\n",
    "eval_dataset = TUHAbnormal(path=os.path.join(tuab_path, \"eval\"))\n",
    "\n",
    "# Assign binary target labels based on file path\n",
    "for ds in train_dataset.datasets:\n",
    "    ds.description[\"target\"] = 0 if \"train\\\\normal\" in str(ds.raw.filenames[0]).lower() else 1\n",
    "for ds in eval_dataset.datasets:\n",
    "    ds.description[\"target\"] = 0 if \"eval\\\\normal\" in str(ds.raw.filenames[0]).lower() else 1\n",
    "\n",
    "# Define a fixed set of EEG channels to keep\n",
    "fixed_channels = [\n",
    "    'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF',\n",
    "    'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF',\n",
    "    'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF',\n",
    "    'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF',\n",
    "    'EEG A1-REF', 'EEG A2-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'\n",
    "]\n",
    "for ds in train_dataset.datasets + eval_dataset.datasets:\n",
    "    ds.raw.pick_channels([ch for ch in fixed_channels if ch in ds.raw.ch_names])\n",
    "\n",
    "# Split train dataset into normal and abnormal groups\n",
    "train_normal = [ds for ds in train_dataset.datasets if ds.description['target'] == 0]\n",
    "train_abnormal = [ds for ds in train_dataset.datasets if ds.description['target'] == 1]\n",
    "\n",
    "# Remove muscle artifacts from normal training data only\n",
    "for ds in tqdm(train_normal, desc=\"Removing muscle artifacts\"):\n",
    "    ds.raw.load_data()\n",
    "    annotate_muscle_zscore(ds.raw, threshold=4.0, filter_freq=(30, 90))\n",
    "    ds.raw.set_annotations(ds.raw.annotations.delete(\n",
    "        np.where(ds.raw.annotations.description == 'BAD_MUSCLE')[0]\n",
    "    ))\n",
    "\n",
    "# Define common preprocessing steps\n",
    "preprocessors = [\n",
    "    Preprocessor('filter', l_freq=0.5, h_freq=40.),\n",
    "    Preprocessor(lambda x: x * 1e6, picks='eeg')  # Convert to µV\n",
    "]\n",
    "\n",
    "# Apply preprocessing to normal training data\n",
    "for ds in tqdm(train_normal, desc=\"Preprocessing train_normal\"):\n",
    "    ds.raw.load_data()\n",
    "    for p in preprocessors:\n",
    "        p.apply(ds.raw)\n",
    "\n",
    "# Apply preprocessing to abnormal training data\n",
    "for ds in tqdm(train_abnormal, desc=\"Preprocessing train_abnormal\"):\n",
    "    ds.raw.load_data()\n",
    "    for p in preprocessors:\n",
    "        p.apply(ds.raw)\n",
    "\n",
    "# Apply preprocessing to evaluation dataset\n",
    "for ds in tqdm(eval_dataset.datasets, desc=\"Preprocessing eval\"):\n",
    "    ds.raw.load_data()\n",
    "    for p in preprocessors:\n",
    "        p.apply(ds.raw)\n",
    "\n",
    "# Combine processed normal and abnormal training sets\n",
    "train_dataset.datasets = train_normal + train_abnormal\n",
    "\n",
    "# Create sliding windows from training and evaluation datasets\n",
    "train_windows = create_fixed_length_windows(\n",
    "    train_dataset,\n",
    "    start_offset_samples=0,\n",
    "    window_size_samples=1000,\n",
    "    window_stride_samples=1000,\n",
    "    drop_last_window=True,\n",
    "    preload=True\n",
    ")\n",
    "eval_windows = create_fixed_length_windows(\n",
    "    eval_dataset,\n",
    "    start_offset_samples=0,\n",
    "    window_size_samples=1000,\n",
    "    window_stride_samples=1000,\n",
    "    drop_last_window=True,\n",
    "    preload=True\n",
    ")\n",
    "\n",
    "# Extract class labels from training windows\n",
    "y_train = [ds.description.get(\"target\", -1) for ds in train_windows.datasets]\n",
    "print(\"Label distribution before balancing:\", Counter(y_train))\n",
    "\n",
    "# Pad all windowed EEG data to have consistent channel size\n",
    "max_chans = max(ds[0].shape[0] for ds in train_windows)\n",
    "X = torch.stack([\n",
    "    torch.nn.functional.pad(torch.tensor(ds[0]), (0, 0, 0, max_chans - ds[0].shape[0]))\n",
    "    for ds in train_windows\n",
    "])\n",
    "y = torch.tensor([ds[1] for ds in train_windows])\n",
    "\n",
    "# Use random oversampling to balance class distribution\n",
    "X_np = X.numpy().reshape(X.shape[0], -1)\n",
    "ros = RandomOverSampler()\n",
    "X_resampled_np, y_resampled_np = ros.fit_resample(X_np, y.numpy())\n",
    "X_resampled = torch.tensor(X_resampled_np).reshape(-1, max_chans, X.shape[2])\n",
    "y_resampled = torch.tensor(y_resampled_np)\n",
    "\n",
    "# Extract and pad evaluation data\n",
    "X_eval = []\n",
    "y_eval = []\n",
    "for windows_ds in tqdm(eval_windows.datasets, desc=\"Extracting eval windows\"):\n",
    "    for i in range(len(windows_ds)):\n",
    "        window_data, label, _ = windows_ds[i]\n",
    "        padded_data = torch.nn.functional.pad(\n",
    "            torch.tensor(window_data, dtype=torch.float32),\n",
    "            (0, 0, 0, max_chans - window_data.shape[0])\n",
    "        )\n",
    "        X_eval.append(padded_data)\n",
    "        y_eval.append(label)\n",
    "\n",
    "# Convert to tensors\n",
    "X_eval = torch.stack(X_eval)\n",
    "y_eval = torch.tensor(y_eval)\n",
    "\n",
    "# Save processed datasets\n",
    "torch.save(X_eval, \"D:/Models_Data/X_eval.pt\")\n",
    "torch.save(y_eval, \"D:/Models_Data/y_eval.pt\")\n",
    "torch.save(X_resampled, \"D:/Models_Data/X_resampled_final(artifact from normal,no tmax).pt\") \n",
    "torch.save(y_resampled, \"D:/Models_Data/y_resampled_final.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f6d194-591d-4dad-a18e-7b194c429f2e",
   "metadata": {},
   "source": [
    "### MLP Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ca516-b903-4c2d-9737-79410f6cd22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔍 Extracting features: 100%|███████████████████████████████████████████████| 952714/952714 [48:33:39<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: X_feat.pt, y_resampled.pt, X_resampled.pt, max_chans.pt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pycatch22 import catch22_all\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the names of the features to be computed\n",
    "with open(\"selected_feature_names.txt\", \"r\") as f:\n",
    "    selected_feature_names = set(line.strip() for line in f.readlines())\n",
    "\n",
    "# Determine which feature types are required\n",
    "need_time = any(\"_time_\" in f for f in selected_feature_names)\n",
    "need_psd = any(\"_psd_\" in f for f in selected_feature_names)\n",
    "need_hjorth = any(\"_hjorth_\" in f for f in selected_feature_names)\n",
    "need_wavelet = any(\"_wavelet_\" in f for f in selected_feature_names)\n",
    "need_catch22 = any(\"_catch22_\" in f for f in selected_feature_names)\n",
    "\n",
    "\n",
    "def extract_features(window):\n",
    "    features = []\n",
    "    for ch_idx, ch in enumerate(window):\n",
    "        ch = np.nan_to_num(ch, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if np.all(ch == ch[0]) or np.std(ch) < 1e-6:\n",
    "            features.extend([0.0 for name in selected_feature_names if name.startswith(f\"ch_{ch_idx}_\")])\n",
    "            continue\n",
    "\n",
    "        # Time-domain features\n",
    "        if need_time:\n",
    "            if f\"ch_{ch_idx}_time_mean\" in selected_feature_names:\n",
    "                features.append(ch.mean())\n",
    "            if f\"ch_{ch_idx}_time_std\" in selected_feature_names:\n",
    "                features.append(ch.std())\n",
    "            if f\"ch_{ch_idx}_time_max\" in selected_feature_names:\n",
    "                features.append(ch.max())\n",
    "            if f\"ch_{ch_idx}_time_min\" in selected_feature_names:\n",
    "                features.append(ch.min())\n",
    "            if f\"ch_{ch_idx}_time_skew\" in selected_feature_names:\n",
    "                features.append(skew(ch))\n",
    "            if f\"ch_{ch_idx}_time_kurtosis\" in selected_feature_names:\n",
    "                features.append(kurtosis(ch))\n",
    "\n",
    "        # Power Spectral Density features\n",
    "        if need_psd:\n",
    "            freqs, psd = welch(ch, fs=100, nperseg=256)\n",
    "            if f\"ch_{ch_idx}_psd_delta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 0.5) & (freqs < 4)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_theta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 4) & (freqs < 8)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_alpha\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 8) & (freqs < 13)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_beta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 13) & (freqs < 30)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_gamma\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 30) & (freqs < 40)].mean())\n",
    "\n",
    "        # Hjorth parameters\n",
    "        if need_hjorth:\n",
    "            d1, d2 = np.diff(ch), np.diff(np.diff(ch))\n",
    "            if f\"ch_{ch_idx}_hjorth_var\" in selected_feature_names:\n",
    "                features.append(np.var(ch))\n",
    "            if f\"ch_{ch_idx}_hjorth_mob\" in selected_feature_names:\n",
    "                features.append(np.std(d1) / (np.std(ch) + 1e-8))\n",
    "            if f\"ch_{ch_idx}_hjorth_comp\" in selected_feature_names:\n",
    "                features.append(np.std(d2) / (np.std(d1) + 1e-8))\n",
    "\n",
    "        # Wavelet-based features\n",
    "        if need_wavelet:\n",
    "            coeffs = pywt.wavedec(ch, 'db4', level=3)\n",
    "            for i, c in enumerate(coeffs):\n",
    "                key = f\"ch_{ch_idx}_wavelet_cD{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.sqrt(np.sum(c ** 2)))\n",
    "\n",
    "        # Catch22 features\n",
    "        if need_catch22:\n",
    "            c22 = catch22_all(ch)[\"values\"]\n",
    "            for i, val in enumerate(c22):\n",
    "                key = f\"ch_{ch_idx}_catch22_{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "\n",
    "# Load preprocessed data from disk\n",
    "X_resampled = torch.load(\"D:/Models_Data/X_resampled_final(artifact from normal,no tmax).pt\")\n",
    "y_resampled = torch.load(\"D:/Models_Data/y_resampled_final.pt\")\n",
    "\n",
    "X_feat = []\n",
    "\n",
    "# Extract features from each signal window\n",
    "for signal in tqdm(X_resampled, desc=\"Extracting features\"):\n",
    "    signal_np = signal.numpy()\n",
    "    feats = extract_features(signal_np)\n",
    "    X_feat.append(torch.tensor(feats, dtype=torch.float32))\n",
    "\n",
    "X_feat = torch.stack(X_feat)\n",
    "\n",
    "# Save the extracted features\n",
    "torch.save(X_feat, \"D:/Models_Data/X_feat.pt\")\n",
    "\n",
    "print(\"Saved: X_feat.pt, y_resampled.pt, X_resampled.pt, max_chans.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752c16e-7c1c-4004-913a-b4e15de3dfab",
   "metadata": {},
   "source": [
    "## MLP Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90d20d-0965-42fb-919c-846f8cd9ede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scaler saved to scaler.pkl\n",
      "✅ Using 168 features extracted directly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obass\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Epoch 001 | Acc: 0.779 | Prec: 0.798 | Rec: 0.746 | F1: 0.771\n",
      "✅ New best model saved.\n",
      "📊 Epoch 002 | Acc: 0.788 | Prec: 0.825 | Rec: 0.731 | F1: 0.775\n",
      "✅ New best model saved.\n",
      "📊 Epoch 003 | Acc: 0.792 | Prec: 0.849 | Rec: 0.711 | F1: 0.774\n",
      "📊 Epoch 004 | Acc: 0.798 | Prec: 0.845 | Rec: 0.729 | F1: 0.783\n",
      "✅ New best model saved.\n",
      "📊 Epoch 005 | Acc: 0.802 | Prec: 0.838 | Rec: 0.748 | F1: 0.790\n",
      "✅ New best model saved.\n",
      "📊 Epoch 006 | Acc: 0.806 | Prec: 0.828 | Rec: 0.772 | F1: 0.799\n",
      "✅ New best model saved.\n",
      "📊 Epoch 007 | Acc: 0.806 | Prec: 0.856 | Rec: 0.735 | F1: 0.791\n",
      "📊 Epoch 008 | Acc: 0.809 | Prec: 0.855 | Rec: 0.744 | F1: 0.796\n",
      "📊 Epoch 009 | Acc: 0.811 | Prec: 0.857 | Rec: 0.745 | F1: 0.797\n",
      "📊 Epoch 010 | Acc: 0.812 | Prec: 0.853 | Rec: 0.753 | F1: 0.800\n",
      "✅ New best model saved.\n",
      "📊 Epoch 011 | Acc: 0.811 | Prec: 0.835 | Rec: 0.776 | F1: 0.804\n",
      "✅ New best model saved.\n",
      "📊 Epoch 012 | Acc: 0.814 | Prec: 0.859 | Rec: 0.752 | F1: 0.802\n",
      "📊 Epoch 013 | Acc: 0.815 | Prec: 0.869 | Rec: 0.742 | F1: 0.801\n",
      "📊 Epoch 014 | Acc: 0.818 | Prec: 0.847 | Rec: 0.776 | F1: 0.810\n",
      "✅ New best model saved.\n",
      "📊 Epoch 015 | Acc: 0.818 | Prec: 0.866 | Rec: 0.752 | F1: 0.805\n",
      "📊 Epoch 016 | Acc: 0.819 | Prec: 0.854 | Rec: 0.770 | F1: 0.810\n",
      "📊 Epoch 017 | Acc: 0.820 | Prec: 0.846 | Rec: 0.782 | F1: 0.813\n",
      "✅ New best model saved.\n",
      "📊 Epoch 018 | Acc: 0.821 | Prec: 0.854 | Rec: 0.774 | F1: 0.812\n",
      "📊 Epoch 019 | Acc: 0.822 | Prec: 0.860 | Rec: 0.770 | F1: 0.813\n",
      "📊 Epoch 020 | Acc: 0.823 | Prec: 0.859 | Rec: 0.772 | F1: 0.814\n",
      "✅ New best model saved.\n",
      "📊 Epoch 021 | Acc: 0.822 | Prec: 0.874 | Rec: 0.752 | F1: 0.809\n",
      "📊 Epoch 022 | Acc: 0.821 | Prec: 0.875 | Rec: 0.748 | F1: 0.807\n",
      "📊 Epoch 023 | Acc: 0.824 | Prec: 0.862 | Rec: 0.770 | F1: 0.814\n",
      "📊 Epoch 024 | Acc: 0.824 | Prec: 0.856 | Rec: 0.779 | F1: 0.816\n",
      "✅ New best model saved.\n",
      "📊 Epoch 025 | Acc: 0.824 | Prec: 0.877 | Rec: 0.754 | F1: 0.811\n",
      "📊 Epoch 026 | Acc: 0.826 | Prec: 0.853 | Rec: 0.788 | F1: 0.819\n",
      "✅ New best model saved.\n",
      "📊 Epoch 027 | Acc: 0.825 | Prec: 0.868 | Rec: 0.765 | F1: 0.814\n",
      "📊 Epoch 028 | Acc: 0.817 | Prec: 0.870 | Rec: 0.745 | F1: 0.803\n",
      "📊 Epoch 029 | Acc: 0.827 | Prec: 0.854 | Rec: 0.789 | F1: 0.820\n",
      "✅ New best model saved.\n",
      "📊 Epoch 030 | Acc: 0.825 | Prec: 0.875 | Rec: 0.760 | F1: 0.813\n",
      "📊 Epoch 031 | Acc: 0.828 | Prec: 0.853 | Rec: 0.791 | F1: 0.821\n",
      "✅ New best model saved.\n",
      "📊 Epoch 032 | Acc: 0.826 | Prec: 0.853 | Rec: 0.787 | F1: 0.819\n",
      "📊 Epoch 033 | Acc: 0.825 | Prec: 0.866 | Rec: 0.769 | F1: 0.815\n",
      "📊 Epoch 034 | Acc: 0.824 | Prec: 0.830 | Rec: 0.814 | F1: 0.822\n",
      "✅ New best model saved.\n",
      "📊 Epoch 035 | Acc: 0.830 | Prec: 0.863 | Rec: 0.783 | F1: 0.821\n",
      "📊 Epoch 036 | Acc: 0.829 | Prec: 0.864 | Rec: 0.781 | F1: 0.820\n",
      "📊 Epoch 037 | Acc: 0.827 | Prec: 0.872 | Rec: 0.767 | F1: 0.816\n",
      "📊 Epoch 038 | Acc: 0.827 | Prec: 0.882 | Rec: 0.754 | F1: 0.813\n",
      "📊 Epoch 039 | Acc: 0.831 | Prec: 0.861 | Rec: 0.791 | F1: 0.824\n",
      "✅ New best model saved.\n",
      "📊 Epoch 040 | Acc: 0.829 | Prec: 0.875 | Rec: 0.768 | F1: 0.818\n",
      "📊 Epoch 041 | Acc: 0.830 | Prec: 0.872 | Rec: 0.773 | F1: 0.819\n",
      "📊 Epoch 042 | Acc: 0.829 | Prec: 0.885 | Rec: 0.757 | F1: 0.816\n",
      "📊 Epoch 043 | Acc: 0.831 | Prec: 0.867 | Rec: 0.783 | F1: 0.823\n",
      "📊 Epoch 044 | Acc: 0.831 | Prec: 0.862 | Rec: 0.788 | F1: 0.823\n",
      "📊 Epoch 045 | Acc: 0.830 | Prec: 0.874 | Rec: 0.771 | F1: 0.819\n",
      "📊 Epoch 046 | Acc: 0.836 | Prec: 0.865 | Rec: 0.795 | F1: 0.829\n",
      "✅ New best model saved.\n",
      "📊 Epoch 047 | Acc: 0.834 | Prec: 0.871 | Rec: 0.784 | F1: 0.826\n",
      "📊 Epoch 048 | Acc: 0.833 | Prec: 0.880 | Rec: 0.773 | F1: 0.823\n",
      "📊 Epoch 049 | Acc: 0.824 | Prec: 0.900 | Rec: 0.729 | F1: 0.805\n",
      "📊 Epoch 050 | Acc: 0.836 | Prec: 0.871 | Rec: 0.787 | F1: 0.827\n",
      "📊 Epoch 051 | Acc: 0.834 | Prec: 0.877 | Rec: 0.777 | F1: 0.824\n",
      "📊 Epoch 052 | Acc: 0.836 | Prec: 0.869 | Rec: 0.791 | F1: 0.828\n",
      "📊 Epoch 053 | Acc: 0.837 | Prec: 0.875 | Rec: 0.785 | F1: 0.828\n",
      "📊 Epoch 054 | Acc: 0.833 | Prec: 0.890 | Rec: 0.760 | F1: 0.820\n",
      "📊 Epoch 055 | Acc: 0.836 | Prec: 0.874 | Rec: 0.787 | F1: 0.828\n",
      "📊 Epoch 056 | Acc: 0.837 | Prec: 0.881 | Rec: 0.778 | F1: 0.826\n",
      "📊 Epoch 057 | Acc: 0.837 | Prec: 0.866 | Rec: 0.797 | F1: 0.830\n",
      "✅ New best model saved.\n",
      "📊 Epoch 058 | Acc: 0.835 | Prec: 0.882 | Rec: 0.772 | F1: 0.824\n",
      "📊 Epoch 059 | Acc: 0.837 | Prec: 0.864 | Rec: 0.800 | F1: 0.831\n",
      "✅ New best model saved.\n",
      "📊 Epoch 060 | Acc: 0.837 | Prec: 0.881 | Rec: 0.781 | F1: 0.828\n",
      "📊 Epoch 061 | Acc: 0.835 | Prec: 0.877 | Rec: 0.779 | F1: 0.826\n",
      "📊 Epoch 062 | Acc: 0.836 | Prec: 0.880 | Rec: 0.779 | F1: 0.826\n",
      "📊 Epoch 063 | Acc: 0.838 | Prec: 0.876 | Rec: 0.789 | F1: 0.830\n",
      "📊 Epoch 064 | Acc: 0.836 | Prec: 0.881 | Rec: 0.775 | F1: 0.825\n",
      "📊 Epoch 065 | Acc: 0.837 | Prec: 0.880 | Rec: 0.782 | F1: 0.828\n",
      "📊 Epoch 066 | Acc: 0.838 | Prec: 0.870 | Rec: 0.795 | F1: 0.831\n",
      "✅ New best model saved.\n",
      "📊 Epoch 067 | Acc: 0.839 | Prec: 0.873 | Rec: 0.793 | F1: 0.831\n",
      "✅ New best model saved.\n",
      "📊 Epoch 068 | Acc: 0.839 | Prec: 0.868 | Rec: 0.799 | F1: 0.832\n",
      "✅ New best model saved.\n",
      "📊 Epoch 069 | Acc: 0.839 | Prec: 0.870 | Rec: 0.797 | F1: 0.832\n",
      "📊 Epoch 070 | Acc: 0.839 | Prec: 0.870 | Rec: 0.798 | F1: 0.833\n",
      "✅ New best model saved.\n",
      "📊 Epoch 071 | Acc: 0.838 | Prec: 0.881 | Rec: 0.781 | F1: 0.828\n",
      "📊 Epoch 072 | Acc: 0.838 | Prec: 0.886 | Rec: 0.776 | F1: 0.827\n",
      "📊 Epoch 073 | Acc: 0.839 | Prec: 0.863 | Rec: 0.807 | F1: 0.834\n",
      "✅ New best model saved.\n",
      "📊 Epoch 074 | Acc: 0.837 | Prec: 0.889 | Rec: 0.769 | F1: 0.825\n",
      "📊 Epoch 075 | Acc: 0.839 | Prec: 0.871 | Rec: 0.796 | F1: 0.832\n",
      "📊 Epoch 076 | Acc: 0.839 | Prec: 0.872 | Rec: 0.794 | F1: 0.831\n",
      "📊 Epoch 077 | Acc: 0.837 | Prec: 0.873 | Rec: 0.788 | F1: 0.828\n",
      "📊 Epoch 078 | Acc: 0.836 | Prec: 0.891 | Rec: 0.765 | F1: 0.823\n",
      "📊 Epoch 079 | Acc: 0.837 | Prec: 0.884 | Rec: 0.776 | F1: 0.826\n",
      "📊 Epoch 080 | Acc: 0.837 | Prec: 0.888 | Rec: 0.770 | F1: 0.825\n",
      "📊 Epoch 081 | Acc: 0.839 | Prec: 0.878 | Rec: 0.788 | F1: 0.830\n",
      "📊 Epoch 082 | Acc: 0.839 | Prec: 0.877 | Rec: 0.789 | F1: 0.831\n",
      "📊 Epoch 083 | Acc: 0.839 | Prec: 0.883 | Rec: 0.782 | F1: 0.830\n",
      "📊 Epoch 084 | Acc: 0.837 | Prec: 0.880 | Rec: 0.781 | F1: 0.827\n",
      "📊 Epoch 085 | Acc: 0.839 | Prec: 0.880 | Rec: 0.784 | F1: 0.829\n",
      "📊 Epoch 086 | Acc: 0.839 | Prec: 0.868 | Rec: 0.800 | F1: 0.833\n",
      "📊 Epoch 087 | Acc: 0.836 | Prec: 0.894 | Rec: 0.762 | F1: 0.822\n",
      "📊 Epoch 088 | Acc: 0.839 | Prec: 0.881 | Rec: 0.783 | F1: 0.829\n",
      "📊 Epoch 089 | Acc: 0.838 | Prec: 0.881 | Rec: 0.783 | F1: 0.829\n",
      "📊 Epoch 090 | Acc: 0.840 | Prec: 0.879 | Rec: 0.789 | F1: 0.832\n",
      "📊 Epoch 091 | Acc: 0.840 | Prec: 0.874 | Rec: 0.794 | F1: 0.832\n",
      "📊 Epoch 092 | Acc: 0.838 | Prec: 0.870 | Rec: 0.795 | F1: 0.831\n",
      "📊 Epoch 093 | Acc: 0.812 | Prec: 0.922 | Rec: 0.681 | F1: 0.784\n",
      "📊 Epoch 094 | Acc: 0.840 | Prec: 0.876 | Rec: 0.791 | F1: 0.832\n",
      "📊 Epoch 095 | Acc: 0.840 | Prec: 0.875 | Rec: 0.792 | F1: 0.832\n",
      "📊 Epoch 096 | Acc: 0.839 | Prec: 0.882 | Rec: 0.783 | F1: 0.829\n",
      "📊 Epoch 097 | Acc: 0.839 | Prec: 0.883 | Rec: 0.781 | F1: 0.829\n",
      "📊 Epoch 098 | Acc: 0.839 | Prec: 0.886 | Rec: 0.777 | F1: 0.828\n",
      "📊 Epoch 099 | Acc: 0.839 | Prec: 0.884 | Rec: 0.781 | F1: 0.829\n",
      "✅ Best model saved to mlp_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import joblib\n",
    "\n",
    "# Load feature and label tensors\n",
    "X_feat = torch.load(\"D:/Models_Data/X_feat.pt\")\n",
    "y_resampled = torch.load(\"D:/Models_Data/y_resampled_final.pt\")\n",
    "\n",
    "# Align lengths if needed\n",
    "X_feat = X_feat[:len(y_resampled)]\n",
    "y_resampled = y_resampled.long()\n",
    "\n",
    "# Normalize features\n",
    "scaler = RobustScaler()\n",
    "X_feat_scaled_np = scaler.fit_transform(X_feat.numpy())\n",
    "X_feat_scaled = torch.tensor(X_feat_scaled_np, dtype=torch.float32)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"Scaler saved to scaler.pkl\")\n",
    "\n",
    "X_selected = X_feat_scaled\n",
    "print(f\"Using {X_selected.shape[1]} features extracted directly.\")\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train_feat, X_val_feat, y_train, y_val = train_test_split(\n",
    "    X_selected, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_ds = TensorDataset(X_train_feat, y_train)\n",
    "val_ds = TensorDataset(X_val_feat, y_val)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "\n",
    "# Compute class weights for imbalanced data\n",
    "weights = compute_class_weight('balanced', classes=torch.unique(y_train).numpy(), y=y_train.numpy())\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "best_f1 = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "# Define the MLP model\n",
    "class MLPOnly(nn.Module):\n",
    "    def __init__(self, feat_dim=200, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model, loss, optimizer, and scheduler\n",
    "model = MLPOnly(feat_dim=X_selected.shape[1]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor.to(device))\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 100):\n",
    "    model.train()\n",
    "    for feat_batch, labels in train_loader:\n",
    "        feat_batch, labels = feat_batch.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(feat_batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for feat_batch, labels in val_loader:\n",
    "            outputs = model(feat_batch.to(device))\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    scheduler.step(f1)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Acc: {acc:.3f} | Prec: {prec:.3f} | Rec: {rec:.3f} | F1: {f1:.3f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model_state = model.state_dict()\n",
    "        print(\"New best model saved.\")\n",
    "\n",
    "# Save the best-performing model\n",
    "torch.save(best_model_state, \"D:/Models_Data/mlp_best_model.pth\")\n",
    "print(\"Best model saved to mlp_best_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddc9376-5fe6-4b0e-bfdf-7363d9ae05b6",
   "metadata": {},
   "source": [
    "## MLP Model Test (Eval on New unseen Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f7542-c480-41de-be2a-d916f6fde10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:127: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:127: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\obass\\AppData\\Local\\Temp\\ipykernel_13356\\1388660706.py:127: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  model.load_state_dict(torch.load(\"D:\\Models_Data\\mlp_best_model.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded X_eval with shape torch.Size([92599, 21, 1000])\n",
      "✅ Loaded y_eval with shape torch.Size([92599])\n",
      "\n",
      "📊 Evaluation Report on Real Eval Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.86      0.80     49872\n",
      "        True       0.80      0.67      0.73     42727\n",
      "\n",
      "    accuracy                           0.77     92599\n",
      "   macro avg       0.78      0.76      0.76     92599\n",
      "weighted avg       0.77      0.77      0.77     92599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from braindecode.datasets.tuh import TUHAbnormal\n",
    "from braindecode.preprocessing import Preprocessor, preprocess, create_fixed_length_windows\n",
    "from braindecode.datasets.base import BaseConcatDataset\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pycatch22 import catch22_all\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load preprocessed evaluation data\n",
    "X_eval = torch.load(\"D:/Models_Data/X_eval.pt\")\n",
    "y_eval = torch.load(\"D:/Models_Data/y_eval.pt\")\n",
    "\n",
    "print(f\"Loaded X_eval with shape {X_eval.shape}\")\n",
    "print(f\"Loaded y_eval with shape {y_eval.shape}\")\n",
    "\n",
    "# Load selected feature names\n",
    "with open(\"selected_feature_names.txt\", \"r\") as f:\n",
    "    selected_feature_names = set(line.strip() for line in f.readlines())\n",
    "\n",
    "need_time = any(\"_time_\" in f for f in selected_feature_names)\n",
    "need_psd = any(\"_psd_\" in f for f in selected_feature_names)\n",
    "need_hjorth = any(\"_hjorth_\" in f for f in selected_feature_names)\n",
    "need_wavelet = any(\"_wavelet_\" in f for f in selected_feature_names)\n",
    "need_catch22 = any(\"_catch22_\" in f for f in selected_feature_names)\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(window):\n",
    "    features = []\n",
    "    for ch_idx, ch in enumerate(window):\n",
    "        ch = np.nan_to_num(ch, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if np.all(ch == ch[0]) or np.std(ch) < 1e-6:\n",
    "            features.extend([0.0 for name in selected_feature_names if name.startswith(f\"ch_{ch_idx}_\")])\n",
    "            continue\n",
    "\n",
    "        if need_time:\n",
    "            if f\"ch_{ch_idx}_time_mean\" in selected_feature_names:\n",
    "                features.append(ch.mean())\n",
    "            if f\"ch_{ch_idx}_time_std\" in selected_feature_names:\n",
    "                features.append(ch.std())\n",
    "            if f\"ch_{ch_idx}_time_max\" in selected_feature_names:\n",
    "                features.append(ch.max())\n",
    "            if f\"ch_{ch_idx}_time_min\" in selected_feature_names:\n",
    "                features.append(ch.min())\n",
    "            if f\"ch_{ch_idx}_time_skew\" in selected_feature_names:\n",
    "                features.append(skew(ch))\n",
    "            if f\"ch_{ch_idx}_time_kurtosis\" in selected_feature_names:\n",
    "                features.append(kurtosis(ch))\n",
    "\n",
    "        if need_psd:\n",
    "            freqs, psd = welch(ch, fs=100, nperseg=256)\n",
    "            if f\"ch_{ch_idx}_psd_delta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 0.5) & (freqs < 4)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_theta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 4) & (freqs < 8)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_alpha\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 8) & (freqs < 13)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_beta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 13) & (freqs < 30)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_gamma\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 30) & (freqs < 40)].mean())\n",
    "\n",
    "        if need_hjorth:\n",
    "            d1, d2 = np.diff(ch), np.diff(np.diff(ch))\n",
    "            if f\"ch_{ch_idx}_hjorth_var\" in selected_feature_names:\n",
    "                features.append(np.var(ch))\n",
    "            if f\"ch_{ch_idx}_hjorth_mob\" in selected_feature_names:\n",
    "                features.append(np.std(d1) / (np.std(ch) + 1e-8))\n",
    "            if f\"ch_{ch_idx}_hjorth_comp\" in selected_feature_names:\n",
    "                features.append(np.std(d2) / (np.std(d1) + 1e-8))\n",
    "\n",
    "        if need_wavelet:\n",
    "            coeffs = pywt.wavedec(ch, 'db4', level=3)\n",
    "            for i, c in enumerate(coeffs):\n",
    "                key = f\"ch_{ch_idx}_wavelet_cD{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.sqrt(np.sum(c ** 2)))\n",
    "\n",
    "        if need_catch22:\n",
    "            c22 = catch22_all(ch)[\"values\"]\n",
    "            for i, val in enumerate(c22):\n",
    "                key = f\"ch_{ch_idx}_catch22_{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "# Uncomment to extract features (if not yet saved)\n",
    "# X_eval_feat = [torch.tensor(extract_features(sig.numpy())) for sig in tqdm(X_eval, desc=\"Extracting eval features\")]\n",
    "# X_eval_feat = torch.stack(X_eval_feat)\n",
    "# torch.save(X_eval_feat, \"X_eval_feat.pt\")\n",
    "# torch.save(y_eval, \"y_eval.pt\")\n",
    "\n",
    "# Load previously saved feature data\n",
    "X_eval_feat = torch.load(\"X_eval_feat.pt\")\n",
    "y_eval = torch.load(\"y_eval.pt\")\n",
    "\n",
    "# Scale features using the saved scaler\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "X_eval_scaled_np = scaler.transform(X_eval_feat.numpy())\n",
    "X_eval_scaled = torch.tensor(X_eval_scaled_np, dtype=torch.float32)\n",
    "\n",
    "# Define the MLP model\n",
    "class MLPOnly(nn.Module):\n",
    "    def __init__(self, feat_dim=200, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Load and evaluate the model\n",
    "model = MLPOnly(feat_dim=X_eval_scaled.shape[1])\n",
    "model.load_state_dict(torch.load(\"D:/Models_Data/mlp_best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(X_eval_scaled).argmax(dim=1)\n",
    "\n",
    "# Print evaluation report\n",
    "print(\"\\nEvaluation Report on Evaluation Dataset\")\n",
    "print(classification_report(y_eval, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b580b-9d36-48d7-8f01-bf406ac908e0",
   "metadata": {},
   "source": [
    "### pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead1cea-3225-4242-97c3-bda453bd8f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\obass\\Desktop\\linux_shared\\v3.0.1\\edf\\eval\\abnormal\\01_tcp_ar\\aaaaabdo_s003_t000.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 304249  =      0.000 ...  1216.996 secs...\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "🧪 Extracting features: 100%|████████████████████████████████████████████████████████| 303/303 [00:43<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Abnormal segments (conf > 0.9): 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pycatch22 import catch22_all\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Define the MLP model architecture\n",
    "class MLPOnly(nn.Module):\n",
    "    def __init__(self, feat_dim=168, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Load pre-trained model and feature scaler\n",
    "model = MLPOnly()\n",
    "model.load_state_dict(torch.load(r\"D:/Models_Data/mlp_best_model.pth\"))\n",
    "model.eval()\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Load EEG data from EDF file\n",
    "edf_path = r\"C:/Users/obass/Desktop/linux_shared/v3.0.1/edf/eval/abnormal/01_tcp_ar/aaaaabdo_s003_t000.edf\"\n",
    "raw = mne.io.read_raw_edf(edf_path, preload=True)\n",
    "raw.pick_types(eeg=True)\n",
    "raw.filter(0.5, 40.)\n",
    "raw._data *= 1e6  # Convert signal to microvolts\n",
    "\n",
    "# Select a fixed set of EEG channels\n",
    "fixed_channels = [\n",
    "    'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF',\n",
    "    'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF',\n",
    "    'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF',\n",
    "    'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF',\n",
    "    'EEG A1-REF', 'EEG A2-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'\n",
    "]\n",
    "raw.pick_channels([ch for ch in fixed_channels if ch in raw.ch_names])\n",
    "\n",
    "# Warn if any expected channels are missing\n",
    "if len(raw.ch_names) < len(fixed_channels):\n",
    "    print(\"Warning: Some expected EEG channels are missing from the EDF file.\")\n",
    "\n",
    "# Create fixed-length non-overlapping windows from the EEG data\n",
    "X = raw.get_data()\n",
    "sampling_rate = 100\n",
    "window_size = 1000\n",
    "stride = 1000\n",
    "num_windows = (X.shape[1] - window_size) // stride\n",
    "\n",
    "X_windows = []\n",
    "for i in range(num_windows):\n",
    "    start = i * stride\n",
    "    end = start + window_size\n",
    "    win = X[:, start:end]\n",
    "    if win.shape[1] == window_size:\n",
    "        X_windows.append(torch.tensor(win, dtype=torch.float32))\n",
    "X_eval = torch.stack(X_windows)\n",
    "\n",
    "# Load names of selected features to extract\n",
    "with open(\"selected_feature_names.txt\", \"r\") as f:\n",
    "    selected_feature_names = set(line.strip() for line in f.readlines())\n",
    "\n",
    "# Determine which types of features are needed\n",
    "need_time = any(\"_time_\" in f for f in selected_feature_names)\n",
    "need_psd = any(\"_psd_\" in f for f in selected_feature_names)\n",
    "need_hjorth = any(\"_hjorth_\" in f for f in selected_feature_names)\n",
    "need_wavelet = any(\"_wavelet_\" in f for f in selected_feature_names)\n",
    "need_catch22 = any(\"_catch22_\" in f for f in selected_feature_names)\n",
    "\n",
    "feature_freq_bands = []\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(window):\n",
    "    features = []\n",
    "    for ch_idx, ch in enumerate(window):\n",
    "        ch = np.nan_to_num(ch, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if np.all(ch == ch[0]) or np.std(ch) < 1e-6:\n",
    "            features.extend([0.0 for name in selected_feature_names if name.startswith(f\"ch_{ch_idx}_\")])\n",
    "            continue\n",
    "        if need_time:\n",
    "            features += [\n",
    "                ch.mean() if f\"ch_{ch_idx}_time_mean\" in selected_feature_names else None,\n",
    "                ch.std() if f\"ch_{ch_idx}_time_std\" in selected_feature_names else None,\n",
    "                ch.max() if f\"ch_{ch_idx}_time_max\" in selected_feature_names else None,\n",
    "                ch.min() if f\"ch_{ch_idx}_time_min\" in selected_feature_names else None,\n",
    "                skew(ch) if f\"ch_{ch_idx}_time_skew\" in selected_feature_names else None,\n",
    "                kurtosis(ch) if f\"ch_{ch_idx}_time_kurtosis\" in selected_feature_names else None\n",
    "            ]\n",
    "        if need_psd:\n",
    "            freqs, psd = welch(ch, fs=sampling_rate, nperseg=256)\n",
    "            band_power = {\n",
    "                \"delta\": psd[(freqs >= 0.5) & (freqs < 4)].mean(),\n",
    "                \"theta\": psd[(freqs >= 4) & (freqs < 8)].mean(),\n",
    "                \"alpha\": psd[(freqs >= 8) & (freqs < 13)].mean(),\n",
    "                \"beta\": psd[(freqs >= 13) & (freqs < 30)].mean(),\n",
    "                \"gamma\": psd[(freqs >= 30) & (freqs < 40)].mean()\n",
    "            }\n",
    "            feature_freq_bands.append(band_power)\n",
    "            features += [\n",
    "                band_power['delta'] if f\"ch_{ch_idx}_psd_delta\" in selected_feature_names else None,\n",
    "                band_power['theta'] if f\"ch_{ch_idx}_psd_theta\" in selected_feature_names else None,\n",
    "                band_power['alpha'] if f\"ch_{ch_idx}_psd_alpha\" in selected_feature_names else None,\n",
    "                band_power['beta'] if f\"ch_{ch_idx}_psd_beta\" in selected_feature_names else None,\n",
    "                band_power['gamma'] if f\"ch_{ch_idx}_psd_gamma\" in selected_feature_names else None\n",
    "            ]\n",
    "        if need_hjorth:\n",
    "            d1, d2 = np.diff(ch), np.diff(np.diff(ch))\n",
    "            features += [\n",
    "                np.var(ch) if f\"ch_{ch_idx}_hjorth_var\" in selected_feature_names else None,\n",
    "                np.std(d1) / (np.std(ch) + 1e-8) if f\"ch_{ch_idx}_hjorth_mob\" in selected_feature_names else None,\n",
    "                np.std(d2) / (np.std(d1) + 1e-8) if f\"ch_{ch_idx}_hjorth_comp\" in selected_feature_names else None\n",
    "            ]\n",
    "        if need_wavelet:\n",
    "            coeffs = pywt.wavedec(ch, 'db4', level=3)\n",
    "            for i, c in enumerate(coeffs):\n",
    "                key = f\"ch_{ch_idx}_wavelet_cD{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.sqrt(np.sum(c ** 2)))\n",
    "        if need_catch22:\n",
    "            c22 = catch22_all(ch)[\"values\"]\n",
    "            for i, val in enumerate(c22):\n",
    "                key = f\"ch_{ch_idx}_catch22_{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "    return np.array([f for f in features if f is not None], dtype=np.float32)\n",
    "\n",
    "# Extract features for each window\n",
    "X_feat = [extract_features(w.numpy()) for w in tqdm(X_eval, desc=\"Extracting features\")]\n",
    "X_feat = torch.tensor(np.stack(X_feat), dtype=torch.float32)\n",
    "\n",
    "# Normalize features using the pre-fitted scaler\n",
    "X_scaled = torch.tensor(scaler.transform(X_feat.numpy()), dtype=torch.float32)\n",
    "\n",
    "# Run model inference\n",
    "with torch.no_grad():\n",
    "    logits = model(X_scaled)\n",
    "    probs = softmax(logits, dim=1)\n",
    "    preds = probs.argmax(dim=1)\n",
    "    confidences = probs.max(dim=1).values\n",
    "\n",
    "# Identify windows classified as abnormal with high confidence\n",
    "abnormal_windows = (preds == 1) & (confidences > 0.9)\n",
    "abnormal_indices = torch.nonzero(abnormal_windows).cpu().numpy()\n",
    "if abnormal_indices.ndim == 0:\n",
    "    abnormal_indices = abnormal_indices.reshape(1)\n",
    "\n",
    "# Report number of abnormal windows detected\n",
    "print(\"Abnormal segments with confidence > 0.9:\", len(abnormal_indices))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

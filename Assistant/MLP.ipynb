{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a21aab-be63-45a3-a669-939850988f1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# üß† EEG Classification Pipeline ‚Äì Step-by-Step Guide\n",
    "\n",
    "## üß† Step 1: Setup and Dataset Loading\n",
    "- Set logging level for MNE to avoid cluttered output.\n",
    "- Set dataset path (`tuab_path`) pointing to TUAB `.edf` folder.\n",
    "- Load train and eval datasets from the TUAB abnormal dataset using `TUHAbnormal`.\n",
    "\n",
    "---\n",
    "\n",
    "## üè∑ Step 2: Assign Labels (Normal = 0, Abnormal = 1)\n",
    "- Iterate over each dataset in train and eval sets.\n",
    "- Check if the path contains `\"normal\"` to assign `target = 0`, otherwise `target = 1`.\n",
    "\n",
    "---\n",
    "\n",
    "## üéß Step 3: Select Common EEG Channels\n",
    "- Define a list of 21 standard EEG channels.\n",
    "- Filter each dataset to keep only those common channels.\n",
    "\n",
    "---\n",
    "\n",
    "## üí• Step 4: Handle Artifacts in Normal Train Samples\n",
    "- Split train dataset into `train_normal` and `train_abnormal`.\n",
    "- For `train_normal`:\n",
    "  - Use `annotate_muscle_zscore()` to detect muscle artifacts.\n",
    "  - Remove those artifacts from the annotations.\n",
    "\n",
    "---\n",
    "\n",
    "## üßπ Step 5: Apply Preprocessing\n",
    "- Define preprocessors:\n",
    "  - Bandpass filtering (0.5‚Äì40 Hz)\n",
    "  - Rescale signal amplitude (Volts ‚Üí ¬µV)\n",
    "- Load EEG into memory for both `train_normal` and `train_abnormal`.\n",
    "- Apply preprocessing to each dataset.\n",
    "- Also preprocess `eval_dataset`.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Step 6: Combine and Window the Data\n",
    "- Recombine cleaned `train_normal` and `train_abnormal`.\n",
    "- Use `create_fixed_length_windows` with:\n",
    "  - Window size: 1000 samples\n",
    "  - No overlap\n",
    "- Apply to both train and eval datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## üè∑ Step 7: Extract Labels and Pad Windows\n",
    "- Extract `target` labels from training windows.\n",
    "- Pad windows to have the same number of channels using PyTorch.\n",
    "- Convert data to tensors: `X`, `y`.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Step 8: Handle Class Imbalance\n",
    "- Flatten `X`, apply random oversampling to balance class distribution.\n",
    "- Reshape oversampled data to `[samples, channels, time]`.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Step 9: Prepare Eval Dataset\n",
    "- Extract and pad windows from eval dataset similarly.\n",
    "- Save `X_eval.pt` and `y_eval.pt` for later testing.\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Step 10: Save Final Balanced Train Data\n",
    "- Save the oversampled and padded tensors: `X_resampled.pt`, `y_resampled.pt`.\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Step 11: Feature Extraction\n",
    "- Load selected feature names from text file (e.g., `\"ch_2_time_mean\"`).\n",
    "- Determine feature types to extract:\n",
    "  - Time-domain stats\n",
    "  - Power Spectral Density (PSD) bands\n",
    "  - Hjorth parameters\n",
    "  - Wavelet energies\n",
    "  - Catch22 features\n",
    "- For each window in `X_resampled`:\n",
    "  - Loop through each channel and compute only selected features.\n",
    "- Stack features into final tensor `X_feat`.\n",
    "- Save as `X_feat.pt`.\n",
    "\n",
    "---\n",
    "\n",
    "## üßº Step 12: Preprocess Features\n",
    "- Load `X_feat` and `y_resampled`.\n",
    "- Apply `RobustScaler` to standardize features.\n",
    "- Save the scaler as `scaler.pkl` for future inference.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÄ Step 13: Split for Training and Validation\n",
    "- Use `train_test_split` with 80/20 stratified split.\n",
    "- Create PyTorch `DataLoaders` for training and validation sets.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Step 14: Compute Class Weights\n",
    "- Compute balanced class weights for `CrossEntropyLoss`.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Step 15: Define the MLP Model\n",
    "- Define `MLPOnly` class:\n",
    "  - Layers: Input ‚Üí 256 ‚Üí 128 ‚Üí 64 ‚Üí 2 (output)\n",
    "  - Each hidden layer: BatchNorm ‚Üí ReLU ‚Üí Dropout\n",
    "- Initialize:\n",
    "  - Model\n",
    "  - Loss: `CrossEntropyLoss` with computed weights\n",
    "  - Optimizer: `Adam`\n",
    "  - Scheduler: `ReduceLROnPlateau`\n",
    "\n",
    "---\n",
    "\n",
    "## üèãÔ∏è Step 16: Train the MLP\n",
    "- Loop through epochs:\n",
    "  - Train on batches with `.backward()` and `optimizer.step()`\n",
    "  - Validate after each epoch:\n",
    "    - Compute accuracy, precision, recall, F1\n",
    "    - Use scheduler to adjust learning rate\n",
    "    - Save model if it achieves best F1\n",
    "\n",
    "---\n",
    "\n",
    "## üíæ Step 17: Save the Best Model\n",
    "- Save `state_dict` of the best model as `mlp_best_model.pth`.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Final Outputs\n",
    "- `X_eval.pt`, `y_eval.pt` ‚Äì evaluation data\n",
    "- `X_resampled_final.pt`, `y_resampled_final.pt` ‚Äì balanced training data\n",
    "- `X_feat.pt` ‚Äì handcrafted features\n",
    "- `scaler.pkl` ‚Äì saved feature scaler\n",
    "- `mlp_best_model.pth` ‚Äì trained MLP model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc45f0f-ec4b-41c0-95bd-936651a29754",
   "metadata": {},
   "source": [
    "## Preprocess for both MLP + Deep4Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371eb2a-7a84-4abe-b045-e3d33d3dba5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí• Removing muscle artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1371/1371 [33:15<00:00,  1.46s/it]\n",
      "C:\\Users\\obass\\anaconda3\\Lib\\site-packages\\braindecode\\preprocessing\\preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n",
      "‚öôÔ∏è Preprocessing train_normal: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1371/1371 [12:29<00:00,  1.83it/s]\n",
      "‚öôÔ∏è Preprocessing train_abnormal: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1346/1346 [09:09<00:00,  2.45it/s]\n",
      "‚öôÔ∏è Preprocessing eval safely: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [01:45<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Label distribution before balancing: Counter({0: 1371, 1: 1346})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì• Extracting eval windows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [03:11<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.datasets.tuh import TUHAbnormal\n",
    "from braindecode.preprocessing import Preprocessor, preprocess, create_fixed_length_windows\n",
    "from braindecode.datasets.base import BaseConcatDataset\n",
    "from mne.preprocessing import annotate_muscle_zscore\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress verbose MNE logs\n",
    "os.environ[\"MNE_LOGGING_LEVEL\"] = \"CRITICAL\"\n",
    "mne.set_log_level('CRITICAL')\n",
    "\n",
    "# Base path to TUAB dataset\n",
    "tuab_path = r\"C:\\Users\\obass\\Desktop\\linux_shared\\v3.0.1\\edf\"\n",
    "\n",
    "# Load training and evaluation datasets\n",
    "train_dataset = TUHAbnormal(path=os.path.join(tuab_path, \"train\"))\n",
    "eval_dataset = TUHAbnormal(path=os.path.join(tuab_path, \"eval\"))\n",
    "\n",
    "# Assign binary target labels based on file path\n",
    "for ds in train_dataset.datasets:\n",
    "    ds.description[\"target\"] = 0 if \"train\\\\normal\" in str(ds.raw.filenames[0]).lower() else 1\n",
    "for ds in eval_dataset.datasets:\n",
    "    ds.description[\"target\"] = 0 if \"eval\\\\normal\" in str(ds.raw.filenames[0]).lower() else 1\n",
    "\n",
    "# Define a fixed set of EEG channels to keep\n",
    "fixed_channels = [\n",
    "    'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF',\n",
    "    'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF',\n",
    "    'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF',\n",
    "    'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF',\n",
    "    'EEG A1-REF', 'EEG A2-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'\n",
    "]\n",
    "for ds in train_dataset.datasets + eval_dataset.datasets:\n",
    "    ds.raw.pick_channels([ch for ch in fixed_channels if ch in ds.raw.ch_names])\n",
    "\n",
    "# Split train dataset into normal and abnormal groups\n",
    "train_normal = [ds for ds in train_dataset.datasets if ds.description['target'] == 0]\n",
    "train_abnormal = [ds for ds in train_dataset.datasets if ds.description['target'] == 1]\n",
    "\n",
    "# Remove muscle artifacts from normal training data only\n",
    "for ds in tqdm(train_normal, desc=\"Removing muscle artifacts\"):\n",
    "    ds.raw.load_data()\n",
    "    annotate_muscle_zscore(ds.raw, threshold=4.0, filter_freq=(30, 90))\n",
    "    ds.raw.set_annotations(ds.raw.annotations.delete(\n",
    "        np.where(ds.raw.annotations.description == 'BAD_MUSCLE')[0]\n",
    "    ))\n",
    "\n",
    "# Define common preprocessing steps\n",
    "preprocessors = [\n",
    "    Preprocessor('filter', l_freq=0.5, h_freq=40.),\n",
    "    Preprocessor(lambda x: x * 1e6, picks='eeg')  # Convert to ¬µV\n",
    "]\n",
    "\n",
    "# Apply preprocessing to normal training data\n",
    "for ds in tqdm(train_normal, desc=\"Preprocessing train_normal\"):\n",
    "    ds.raw.load_data()\n",
    "    for p in preprocessors:\n",
    "        p.apply(ds.raw)\n",
    "\n",
    "# Apply preprocessing to abnormal training data\n",
    "for ds in tqdm(train_abnormal, desc=\"Preprocessing train_abnormal\"):\n",
    "    ds.raw.load_data()\n",
    "    for p in preprocessors:\n",
    "        p.apply(ds.raw)\n",
    "\n",
    "# Apply preprocessing to evaluation dataset\n",
    "for ds in tqdm(eval_dataset.datasets, desc=\"Preprocessing eval\"):\n",
    "    ds.raw.load_data()\n",
    "    for p in preprocessors:\n",
    "        p.apply(ds.raw)\n",
    "\n",
    "# Combine processed normal and abnormal training sets\n",
    "train_dataset.datasets = train_normal + train_abnormal\n",
    "\n",
    "# Create sliding windows from training and evaluation datasets\n",
    "train_windows = create_fixed_length_windows(\n",
    "    train_dataset,\n",
    "    start_offset_samples=0,\n",
    "    window_size_samples=1000,\n",
    "    window_stride_samples=1000,\n",
    "    drop_last_window=True,\n",
    "    preload=True\n",
    ")\n",
    "eval_windows = create_fixed_length_windows(\n",
    "    eval_dataset,\n",
    "    start_offset_samples=0,\n",
    "    window_size_samples=1000,\n",
    "    window_stride_samples=1000,\n",
    "    drop_last_window=True,\n",
    "    preload=True\n",
    ")\n",
    "\n",
    "# Extract class labels from training windows\n",
    "y_train = [ds.description.get(\"target\", -1) for ds in train_windows.datasets]\n",
    "print(\"Label distribution before balancing:\", Counter(y_train))\n",
    "\n",
    "# Pad all windowed EEG data to have consistent channel size\n",
    "max_chans = max(ds[0].shape[0] for ds in train_windows)\n",
    "X = torch.stack([\n",
    "    torch.nn.functional.pad(torch.tensor(ds[0]), (0, 0, 0, max_chans - ds[0].shape[0]))\n",
    "    for ds in train_windows\n",
    "])\n",
    "y = torch.tensor([ds[1] for ds in train_windows])\n",
    "\n",
    "# Use random oversampling to balance class distribution\n",
    "X_np = X.numpy().reshape(X.shape[0], -1)\n",
    "ros = RandomOverSampler()\n",
    "X_resampled_np, y_resampled_np = ros.fit_resample(X_np, y.numpy())\n",
    "X_resampled = torch.tensor(X_resampled_np).reshape(-1, max_chans, X.shape[2])\n",
    "y_resampled = torch.tensor(y_resampled_np)\n",
    "\n",
    "# Extract and pad evaluation data\n",
    "X_eval = []\n",
    "y_eval = []\n",
    "for windows_ds in tqdm(eval_windows.datasets, desc=\"Extracting eval windows\"):\n",
    "    for i in range(len(windows_ds)):\n",
    "        window_data, label, _ = windows_ds[i]\n",
    "        padded_data = torch.nn.functional.pad(\n",
    "            torch.tensor(window_data, dtype=torch.float32),\n",
    "            (0, 0, 0, max_chans - window_data.shape[0])\n",
    "        )\n",
    "        X_eval.append(padded_data)\n",
    "        y_eval.append(label)\n",
    "\n",
    "# Convert to tensors\n",
    "X_eval = torch.stack(X_eval)\n",
    "y_eval = torch.tensor(y_eval)\n",
    "\n",
    "# Save processed datasets\n",
    "torch.save(X_eval, \"D:/Models_Data/X_eval.pt\")\n",
    "torch.save(y_eval, \"D:/Models_Data/y_eval.pt\")\n",
    "torch.save(X_resampled, \"D:/Models_Data/X_resampled_final(artifact from normal,no tmax).pt\") \n",
    "torch.save(y_resampled, \"D:/Models_Data/y_resampled_final.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f6d194-591d-4dad-a18e-7b194c429f2e",
   "metadata": {},
   "source": [
    "### MLP Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ca516-b903-4c2d-9737-79410f6cd22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 952714/952714 [48:33:39<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: X_feat.pt, y_resampled.pt, X_resampled.pt, max_chans.pt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pycatch22 import catch22_all\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the names of the features to be computed\n",
    "with open(\"selected_feature_names.txt\", \"r\") as f:\n",
    "    selected_feature_names = set(line.strip() for line in f.readlines())\n",
    "\n",
    "# Determine which feature types are required\n",
    "need_time = any(\"_time_\" in f for f in selected_feature_names)\n",
    "need_psd = any(\"_psd_\" in f for f in selected_feature_names)\n",
    "need_hjorth = any(\"_hjorth_\" in f for f in selected_feature_names)\n",
    "need_wavelet = any(\"_wavelet_\" in f for f in selected_feature_names)\n",
    "need_catch22 = any(\"_catch22_\" in f for f in selected_feature_names)\n",
    "\n",
    "\n",
    "def extract_features(window):\n",
    "    features = []\n",
    "    for ch_idx, ch in enumerate(window):\n",
    "        ch = np.nan_to_num(ch, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if np.all(ch == ch[0]) or np.std(ch) < 1e-6:\n",
    "            features.extend([0.0 for name in selected_feature_names if name.startswith(f\"ch_{ch_idx}_\")])\n",
    "            continue\n",
    "\n",
    "        # Time-domain features\n",
    "        if need_time:\n",
    "            if f\"ch_{ch_idx}_time_mean\" in selected_feature_names:\n",
    "                features.append(ch.mean())\n",
    "            if f\"ch_{ch_idx}_time_std\" in selected_feature_names:\n",
    "                features.append(ch.std())\n",
    "            if f\"ch_{ch_idx}_time_max\" in selected_feature_names:\n",
    "                features.append(ch.max())\n",
    "            if f\"ch_{ch_idx}_time_min\" in selected_feature_names:\n",
    "                features.append(ch.min())\n",
    "            if f\"ch_{ch_idx}_time_skew\" in selected_feature_names:\n",
    "                features.append(skew(ch))\n",
    "            if f\"ch_{ch_idx}_time_kurtosis\" in selected_feature_names:\n",
    "                features.append(kurtosis(ch))\n",
    "\n",
    "        # Power Spectral Density features\n",
    "        if need_psd:\n",
    "            freqs, psd = welch(ch, fs=100, nperseg=256)\n",
    "            if f\"ch_{ch_idx}_psd_delta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 0.5) & (freqs < 4)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_theta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 4) & (freqs < 8)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_alpha\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 8) & (freqs < 13)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_beta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 13) & (freqs < 30)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_gamma\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 30) & (freqs < 40)].mean())\n",
    "\n",
    "        # Hjorth parameters\n",
    "        if need_hjorth:\n",
    "            d1, d2 = np.diff(ch), np.diff(np.diff(ch))\n",
    "            if f\"ch_{ch_idx}_hjorth_var\" in selected_feature_names:\n",
    "                features.append(np.var(ch))\n",
    "            if f\"ch_{ch_idx}_hjorth_mob\" in selected_feature_names:\n",
    "                features.append(np.std(d1) / (np.std(ch) + 1e-8))\n",
    "            if f\"ch_{ch_idx}_hjorth_comp\" in selected_feature_names:\n",
    "                features.append(np.std(d2) / (np.std(d1) + 1e-8))\n",
    "\n",
    "        # Wavelet-based features\n",
    "        if need_wavelet:\n",
    "            coeffs = pywt.wavedec(ch, 'db4', level=3)\n",
    "            for i, c in enumerate(coeffs):\n",
    "                key = f\"ch_{ch_idx}_wavelet_cD{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.sqrt(np.sum(c ** 2)))\n",
    "\n",
    "        # Catch22 features\n",
    "        if need_catch22:\n",
    "            c22 = catch22_all(ch)[\"values\"]\n",
    "            for i, val in enumerate(c22):\n",
    "                key = f\"ch_{ch_idx}_catch22_{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "\n",
    "# Load preprocessed data from disk\n",
    "X_resampled = torch.load(\"D:/Models_Data/X_resampled_final(artifact from normal,no tmax).pt\")\n",
    "y_resampled = torch.load(\"D:/Models_Data/y_resampled_final.pt\")\n",
    "\n",
    "X_feat = []\n",
    "\n",
    "# Extract features from each signal window\n",
    "for signal in tqdm(X_resampled, desc=\"Extracting features\"):\n",
    "    signal_np = signal.numpy()\n",
    "    feats = extract_features(signal_np)\n",
    "    X_feat.append(torch.tensor(feats, dtype=torch.float32))\n",
    "\n",
    "X_feat = torch.stack(X_feat)\n",
    "\n",
    "# Save the extracted features\n",
    "torch.save(X_feat, \"D:/Models_Data/X_feat.pt\")\n",
    "\n",
    "print(\"Saved: X_feat.pt, y_resampled.pt, X_resampled.pt, max_chans.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752c16e-7c1c-4004-913a-b4e15de3dfab",
   "metadata": {},
   "source": [
    "## MLP Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90d20d-0965-42fb-919c-846f8cd9ede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scaler saved to scaler.pkl\n",
      "‚úÖ Using 168 features extracted directly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obass\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Epoch 001 | Acc: 0.779 | Prec: 0.798 | Rec: 0.746 | F1: 0.771\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 002 | Acc: 0.788 | Prec: 0.825 | Rec: 0.731 | F1: 0.775\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 003 | Acc: 0.792 | Prec: 0.849 | Rec: 0.711 | F1: 0.774\n",
      "üìä Epoch 004 | Acc: 0.798 | Prec: 0.845 | Rec: 0.729 | F1: 0.783\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 005 | Acc: 0.802 | Prec: 0.838 | Rec: 0.748 | F1: 0.790\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 006 | Acc: 0.806 | Prec: 0.828 | Rec: 0.772 | F1: 0.799\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 007 | Acc: 0.806 | Prec: 0.856 | Rec: 0.735 | F1: 0.791\n",
      "üìä Epoch 008 | Acc: 0.809 | Prec: 0.855 | Rec: 0.744 | F1: 0.796\n",
      "üìä Epoch 009 | Acc: 0.811 | Prec: 0.857 | Rec: 0.745 | F1: 0.797\n",
      "üìä Epoch 010 | Acc: 0.812 | Prec: 0.853 | Rec: 0.753 | F1: 0.800\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 011 | Acc: 0.811 | Prec: 0.835 | Rec: 0.776 | F1: 0.804\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 012 | Acc: 0.814 | Prec: 0.859 | Rec: 0.752 | F1: 0.802\n",
      "üìä Epoch 013 | Acc: 0.815 | Prec: 0.869 | Rec: 0.742 | F1: 0.801\n",
      "üìä Epoch 014 | Acc: 0.818 | Prec: 0.847 | Rec: 0.776 | F1: 0.810\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 015 | Acc: 0.818 | Prec: 0.866 | Rec: 0.752 | F1: 0.805\n",
      "üìä Epoch 016 | Acc: 0.819 | Prec: 0.854 | Rec: 0.770 | F1: 0.810\n",
      "üìä Epoch 017 | Acc: 0.820 | Prec: 0.846 | Rec: 0.782 | F1: 0.813\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 018 | Acc: 0.821 | Prec: 0.854 | Rec: 0.774 | F1: 0.812\n",
      "üìä Epoch 019 | Acc: 0.822 | Prec: 0.860 | Rec: 0.770 | F1: 0.813\n",
      "üìä Epoch 020 | Acc: 0.823 | Prec: 0.859 | Rec: 0.772 | F1: 0.814\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 021 | Acc: 0.822 | Prec: 0.874 | Rec: 0.752 | F1: 0.809\n",
      "üìä Epoch 022 | Acc: 0.821 | Prec: 0.875 | Rec: 0.748 | F1: 0.807\n",
      "üìä Epoch 023 | Acc: 0.824 | Prec: 0.862 | Rec: 0.770 | F1: 0.814\n",
      "üìä Epoch 024 | Acc: 0.824 | Prec: 0.856 | Rec: 0.779 | F1: 0.816\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 025 | Acc: 0.824 | Prec: 0.877 | Rec: 0.754 | F1: 0.811\n",
      "üìä Epoch 026 | Acc: 0.826 | Prec: 0.853 | Rec: 0.788 | F1: 0.819\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 027 | Acc: 0.825 | Prec: 0.868 | Rec: 0.765 | F1: 0.814\n",
      "üìä Epoch 028 | Acc: 0.817 | Prec: 0.870 | Rec: 0.745 | F1: 0.803\n",
      "üìä Epoch 029 | Acc: 0.827 | Prec: 0.854 | Rec: 0.789 | F1: 0.820\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 030 | Acc: 0.825 | Prec: 0.875 | Rec: 0.760 | F1: 0.813\n",
      "üìä Epoch 031 | Acc: 0.828 | Prec: 0.853 | Rec: 0.791 | F1: 0.821\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 032 | Acc: 0.826 | Prec: 0.853 | Rec: 0.787 | F1: 0.819\n",
      "üìä Epoch 033 | Acc: 0.825 | Prec: 0.866 | Rec: 0.769 | F1: 0.815\n",
      "üìä Epoch 034 | Acc: 0.824 | Prec: 0.830 | Rec: 0.814 | F1: 0.822\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 035 | Acc: 0.830 | Prec: 0.863 | Rec: 0.783 | F1: 0.821\n",
      "üìä Epoch 036 | Acc: 0.829 | Prec: 0.864 | Rec: 0.781 | F1: 0.820\n",
      "üìä Epoch 037 | Acc: 0.827 | Prec: 0.872 | Rec: 0.767 | F1: 0.816\n",
      "üìä Epoch 038 | Acc: 0.827 | Prec: 0.882 | Rec: 0.754 | F1: 0.813\n",
      "üìä Epoch 039 | Acc: 0.831 | Prec: 0.861 | Rec: 0.791 | F1: 0.824\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 040 | Acc: 0.829 | Prec: 0.875 | Rec: 0.768 | F1: 0.818\n",
      "üìä Epoch 041 | Acc: 0.830 | Prec: 0.872 | Rec: 0.773 | F1: 0.819\n",
      "üìä Epoch 042 | Acc: 0.829 | Prec: 0.885 | Rec: 0.757 | F1: 0.816\n",
      "üìä Epoch 043 | Acc: 0.831 | Prec: 0.867 | Rec: 0.783 | F1: 0.823\n",
      "üìä Epoch 044 | Acc: 0.831 | Prec: 0.862 | Rec: 0.788 | F1: 0.823\n",
      "üìä Epoch 045 | Acc: 0.830 | Prec: 0.874 | Rec: 0.771 | F1: 0.819\n",
      "üìä Epoch 046 | Acc: 0.836 | Prec: 0.865 | Rec: 0.795 | F1: 0.829\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 047 | Acc: 0.834 | Prec: 0.871 | Rec: 0.784 | F1: 0.826\n",
      "üìä Epoch 048 | Acc: 0.833 | Prec: 0.880 | Rec: 0.773 | F1: 0.823\n",
      "üìä Epoch 049 | Acc: 0.824 | Prec: 0.900 | Rec: 0.729 | F1: 0.805\n",
      "üìä Epoch 050 | Acc: 0.836 | Prec: 0.871 | Rec: 0.787 | F1: 0.827\n",
      "üìä Epoch 051 | Acc: 0.834 | Prec: 0.877 | Rec: 0.777 | F1: 0.824\n",
      "üìä Epoch 052 | Acc: 0.836 | Prec: 0.869 | Rec: 0.791 | F1: 0.828\n",
      "üìä Epoch 053 | Acc: 0.837 | Prec: 0.875 | Rec: 0.785 | F1: 0.828\n",
      "üìä Epoch 054 | Acc: 0.833 | Prec: 0.890 | Rec: 0.760 | F1: 0.820\n",
      "üìä Epoch 055 | Acc: 0.836 | Prec: 0.874 | Rec: 0.787 | F1: 0.828\n",
      "üìä Epoch 056 | Acc: 0.837 | Prec: 0.881 | Rec: 0.778 | F1: 0.826\n",
      "üìä Epoch 057 | Acc: 0.837 | Prec: 0.866 | Rec: 0.797 | F1: 0.830\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 058 | Acc: 0.835 | Prec: 0.882 | Rec: 0.772 | F1: 0.824\n",
      "üìä Epoch 059 | Acc: 0.837 | Prec: 0.864 | Rec: 0.800 | F1: 0.831\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 060 | Acc: 0.837 | Prec: 0.881 | Rec: 0.781 | F1: 0.828\n",
      "üìä Epoch 061 | Acc: 0.835 | Prec: 0.877 | Rec: 0.779 | F1: 0.826\n",
      "üìä Epoch 062 | Acc: 0.836 | Prec: 0.880 | Rec: 0.779 | F1: 0.826\n",
      "üìä Epoch 063 | Acc: 0.838 | Prec: 0.876 | Rec: 0.789 | F1: 0.830\n",
      "üìä Epoch 064 | Acc: 0.836 | Prec: 0.881 | Rec: 0.775 | F1: 0.825\n",
      "üìä Epoch 065 | Acc: 0.837 | Prec: 0.880 | Rec: 0.782 | F1: 0.828\n",
      "üìä Epoch 066 | Acc: 0.838 | Prec: 0.870 | Rec: 0.795 | F1: 0.831\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 067 | Acc: 0.839 | Prec: 0.873 | Rec: 0.793 | F1: 0.831\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 068 | Acc: 0.839 | Prec: 0.868 | Rec: 0.799 | F1: 0.832\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 069 | Acc: 0.839 | Prec: 0.870 | Rec: 0.797 | F1: 0.832\n",
      "üìä Epoch 070 | Acc: 0.839 | Prec: 0.870 | Rec: 0.798 | F1: 0.833\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 071 | Acc: 0.838 | Prec: 0.881 | Rec: 0.781 | F1: 0.828\n",
      "üìä Epoch 072 | Acc: 0.838 | Prec: 0.886 | Rec: 0.776 | F1: 0.827\n",
      "üìä Epoch 073 | Acc: 0.839 | Prec: 0.863 | Rec: 0.807 | F1: 0.834\n",
      "‚úÖ New best model saved.\n",
      "üìä Epoch 074 | Acc: 0.837 | Prec: 0.889 | Rec: 0.769 | F1: 0.825\n",
      "üìä Epoch 075 | Acc: 0.839 | Prec: 0.871 | Rec: 0.796 | F1: 0.832\n",
      "üìä Epoch 076 | Acc: 0.839 | Prec: 0.872 | Rec: 0.794 | F1: 0.831\n",
      "üìä Epoch 077 | Acc: 0.837 | Prec: 0.873 | Rec: 0.788 | F1: 0.828\n",
      "üìä Epoch 078 | Acc: 0.836 | Prec: 0.891 | Rec: 0.765 | F1: 0.823\n",
      "üìä Epoch 079 | Acc: 0.837 | Prec: 0.884 | Rec: 0.776 | F1: 0.826\n",
      "üìä Epoch 080 | Acc: 0.837 | Prec: 0.888 | Rec: 0.770 | F1: 0.825\n",
      "üìä Epoch 081 | Acc: 0.839 | Prec: 0.878 | Rec: 0.788 | F1: 0.830\n",
      "üìä Epoch 082 | Acc: 0.839 | Prec: 0.877 | Rec: 0.789 | F1: 0.831\n",
      "üìä Epoch 083 | Acc: 0.839 | Prec: 0.883 | Rec: 0.782 | F1: 0.830\n",
      "üìä Epoch 084 | Acc: 0.837 | Prec: 0.880 | Rec: 0.781 | F1: 0.827\n",
      "üìä Epoch 085 | Acc: 0.839 | Prec: 0.880 | Rec: 0.784 | F1: 0.829\n",
      "üìä Epoch 086 | Acc: 0.839 | Prec: 0.868 | Rec: 0.800 | F1: 0.833\n",
      "üìä Epoch 087 | Acc: 0.836 | Prec: 0.894 | Rec: 0.762 | F1: 0.822\n",
      "üìä Epoch 088 | Acc: 0.839 | Prec: 0.881 | Rec: 0.783 | F1: 0.829\n",
      "üìä Epoch 089 | Acc: 0.838 | Prec: 0.881 | Rec: 0.783 | F1: 0.829\n",
      "üìä Epoch 090 | Acc: 0.840 | Prec: 0.879 | Rec: 0.789 | F1: 0.832\n",
      "üìä Epoch 091 | Acc: 0.840 | Prec: 0.874 | Rec: 0.794 | F1: 0.832\n",
      "üìä Epoch 092 | Acc: 0.838 | Prec: 0.870 | Rec: 0.795 | F1: 0.831\n",
      "üìä Epoch 093 | Acc: 0.812 | Prec: 0.922 | Rec: 0.681 | F1: 0.784\n",
      "üìä Epoch 094 | Acc: 0.840 | Prec: 0.876 | Rec: 0.791 | F1: 0.832\n",
      "üìä Epoch 095 | Acc: 0.840 | Prec: 0.875 | Rec: 0.792 | F1: 0.832\n",
      "üìä Epoch 096 | Acc: 0.839 | Prec: 0.882 | Rec: 0.783 | F1: 0.829\n",
      "üìä Epoch 097 | Acc: 0.839 | Prec: 0.883 | Rec: 0.781 | F1: 0.829\n",
      "üìä Epoch 098 | Acc: 0.839 | Prec: 0.886 | Rec: 0.777 | F1: 0.828\n",
      "üìä Epoch 099 | Acc: 0.839 | Prec: 0.884 | Rec: 0.781 | F1: 0.829\n",
      "‚úÖ Best model saved to mlp_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import joblib\n",
    "\n",
    "# Load feature and label tensors\n",
    "X_feat = torch.load(\"D:/Models_Data/X_feat.pt\")\n",
    "y_resampled = torch.load(\"D:/Models_Data/y_resampled_final.pt\")\n",
    "\n",
    "# Align lengths if needed\n",
    "X_feat = X_feat[:len(y_resampled)]\n",
    "y_resampled = y_resampled.long()\n",
    "\n",
    "# Normalize features\n",
    "scaler = RobustScaler()\n",
    "X_feat_scaled_np = scaler.fit_transform(X_feat.numpy())\n",
    "X_feat_scaled = torch.tensor(X_feat_scaled_np, dtype=torch.float32)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"Scaler saved to scaler.pkl\")\n",
    "\n",
    "X_selected = X_feat_scaled\n",
    "print(f\"Using {X_selected.shape[1]} features extracted directly.\")\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train_feat, X_val_feat, y_train, y_val = train_test_split(\n",
    "    X_selected, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_ds = TensorDataset(X_train_feat, y_train)\n",
    "val_ds = TensorDataset(X_val_feat, y_val)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "\n",
    "# Compute class weights for imbalanced data\n",
    "weights = compute_class_weight('balanced', classes=torch.unique(y_train).numpy(), y=y_train.numpy())\n",
    "weights_tensor = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "best_f1 = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "# Define the MLP model\n",
    "class MLPOnly(nn.Module):\n",
    "    def __init__(self, feat_dim=200, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model, loss, optimizer, and scheduler\n",
    "model = MLPOnly(feat_dim=X_selected.shape[1]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor.to(device))\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 100):\n",
    "    model.train()\n",
    "    for feat_batch, labels in train_loader:\n",
    "        feat_batch, labels = feat_batch.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(feat_batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for feat_batch, labels in val_loader:\n",
    "            outputs = model(feat_batch.to(device))\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    scheduler.step(f1)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Acc: {acc:.3f} | Prec: {prec:.3f} | Rec: {rec:.3f} | F1: {f1:.3f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model_state = model.state_dict()\n",
    "        print(\"New best model saved.\")\n",
    "\n",
    "# Save the best-performing model\n",
    "torch.save(best_model_state, \"D:/Models_Data/mlp_best_model.pth\")\n",
    "print(\"Best model saved to mlp_best_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddc9376-5fe6-4b0e-bfdf-7363d9ae05b6",
   "metadata": {},
   "source": [
    "## MLP Model Test (Eval on New unseen Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f7542-c480-41de-be2a-d916f6fde10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:127: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:127: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\obass\\AppData\\Local\\Temp\\ipykernel_13356\\1388660706.py:127: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  model.load_state_dict(torch.load(\"D:\\Models_Data\\mlp_best_model.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded X_eval with shape torch.Size([92599, 21, 1000])\n",
      "‚úÖ Loaded y_eval with shape torch.Size([92599])\n",
      "\n",
      "üìä Evaluation Report on Real Eval Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.86      0.80     49872\n",
      "        True       0.80      0.67      0.73     42727\n",
      "\n",
      "    accuracy                           0.77     92599\n",
      "   macro avg       0.78      0.76      0.76     92599\n",
      "weighted avg       0.77      0.77      0.77     92599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from braindecode.datasets.tuh import TUHAbnormal\n",
    "from braindecode.preprocessing import Preprocessor, preprocess, create_fixed_length_windows\n",
    "from braindecode.datasets.base import BaseConcatDataset\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pycatch22 import catch22_all\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load preprocessed evaluation data\n",
    "X_eval = torch.load(\"D:/Models_Data/X_eval.pt\")\n",
    "y_eval = torch.load(\"D:/Models_Data/y_eval.pt\")\n",
    "\n",
    "print(f\"Loaded X_eval with shape {X_eval.shape}\")\n",
    "print(f\"Loaded y_eval with shape {y_eval.shape}\")\n",
    "\n",
    "# Load selected feature names\n",
    "with open(\"selected_feature_names.txt\", \"r\") as f:\n",
    "    selected_feature_names = set(line.strip() for line in f.readlines())\n",
    "\n",
    "need_time = any(\"_time_\" in f for f in selected_feature_names)\n",
    "need_psd = any(\"_psd_\" in f for f in selected_feature_names)\n",
    "need_hjorth = any(\"_hjorth_\" in f for f in selected_feature_names)\n",
    "need_wavelet = any(\"_wavelet_\" in f for f in selected_feature_names)\n",
    "need_catch22 = any(\"_catch22_\" in f for f in selected_feature_names)\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(window):\n",
    "    features = []\n",
    "    for ch_idx, ch in enumerate(window):\n",
    "        ch = np.nan_to_num(ch, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if np.all(ch == ch[0]) or np.std(ch) < 1e-6:\n",
    "            features.extend([0.0 for name in selected_feature_names if name.startswith(f\"ch_{ch_idx}_\")])\n",
    "            continue\n",
    "\n",
    "        if need_time:\n",
    "            if f\"ch_{ch_idx}_time_mean\" in selected_feature_names:\n",
    "                features.append(ch.mean())\n",
    "            if f\"ch_{ch_idx}_time_std\" in selected_feature_names:\n",
    "                features.append(ch.std())\n",
    "            if f\"ch_{ch_idx}_time_max\" in selected_feature_names:\n",
    "                features.append(ch.max())\n",
    "            if f\"ch_{ch_idx}_time_min\" in selected_feature_names:\n",
    "                features.append(ch.min())\n",
    "            if f\"ch_{ch_idx}_time_skew\" in selected_feature_names:\n",
    "                features.append(skew(ch))\n",
    "            if f\"ch_{ch_idx}_time_kurtosis\" in selected_feature_names:\n",
    "                features.append(kurtosis(ch))\n",
    "\n",
    "        if need_psd:\n",
    "            freqs, psd = welch(ch, fs=100, nperseg=256)\n",
    "            if f\"ch_{ch_idx}_psd_delta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 0.5) & (freqs < 4)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_theta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 4) & (freqs < 8)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_alpha\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 8) & (freqs < 13)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_beta\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 13) & (freqs < 30)].mean())\n",
    "            if f\"ch_{ch_idx}_psd_gamma\" in selected_feature_names:\n",
    "                features.append(psd[(freqs >= 30) & (freqs < 40)].mean())\n",
    "\n",
    "        if need_hjorth:\n",
    "            d1, d2 = np.diff(ch), np.diff(np.diff(ch))\n",
    "            if f\"ch_{ch_idx}_hjorth_var\" in selected_feature_names:\n",
    "                features.append(np.var(ch))\n",
    "            if f\"ch_{ch_idx}_hjorth_mob\" in selected_feature_names:\n",
    "                features.append(np.std(d1) / (np.std(ch) + 1e-8))\n",
    "            if f\"ch_{ch_idx}_hjorth_comp\" in selected_feature_names:\n",
    "                features.append(np.std(d2) / (np.std(d1) + 1e-8))\n",
    "\n",
    "        if need_wavelet:\n",
    "            coeffs = pywt.wavedec(ch, 'db4', level=3)\n",
    "            for i, c in enumerate(coeffs):\n",
    "                key = f\"ch_{ch_idx}_wavelet_cD{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.sqrt(np.sum(c ** 2)))\n",
    "\n",
    "        if need_catch22:\n",
    "            c22 = catch22_all(ch)[\"values\"]\n",
    "            for i, val in enumerate(c22):\n",
    "                key = f\"ch_{ch_idx}_catch22_{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "\n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "# Uncomment to extract features (if not yet saved)\n",
    "# X_eval_feat = [torch.tensor(extract_features(sig.numpy())) for sig in tqdm(X_eval, desc=\"Extracting eval features\")]\n",
    "# X_eval_feat = torch.stack(X_eval_feat)\n",
    "# torch.save(X_eval_feat, \"X_eval_feat.pt\")\n",
    "# torch.save(y_eval, \"y_eval.pt\")\n",
    "\n",
    "# Load previously saved feature data\n",
    "X_eval_feat = torch.load(\"X_eval_feat.pt\")\n",
    "y_eval = torch.load(\"y_eval.pt\")\n",
    "\n",
    "# Scale features using the saved scaler\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "X_eval_scaled_np = scaler.transform(X_eval_feat.numpy())\n",
    "X_eval_scaled = torch.tensor(X_eval_scaled_np, dtype=torch.float32)\n",
    "\n",
    "# Define the MLP model\n",
    "class MLPOnly(nn.Module):\n",
    "    def __init__(self, feat_dim=200, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Load and evaluate the model\n",
    "model = MLPOnly(feat_dim=X_eval_scaled.shape[1])\n",
    "model.load_state_dict(torch.load(\"D:/Models_Data/mlp_best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(X_eval_scaled).argmax(dim=1)\n",
    "\n",
    "# Print evaluation report\n",
    "print(\"\\nEvaluation Report on Evaluation Dataset\")\n",
    "print(classification_report(y_eval, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b580b-9d36-48d7-8f01-bf406ac908e0",
   "metadata": {},
   "source": [
    "### pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead1cea-3225-4242-97c3-bda453bd8f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\obass\\Desktop\\linux_shared\\v3.0.1\\edf\\eval\\abnormal\\01_tcp_ar\\aaaaabdo_s003_t000.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 304249  =      0.000 ...  1216.996 secs...\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1651 samples (6.604 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "üß™ Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 303/303 [00:43<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Abnormal segments (conf > 0.9): 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pycatch22 import catch22_all\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Define the MLP model architecture\n",
    "class MLPOnly(nn.Module):\n",
    "    def __init__(self, feat_dim=168, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Load pre-trained model and feature scaler\n",
    "model = MLPOnly()\n",
    "model.load_state_dict(torch.load(r\"D:/Models_Data/mlp_best_model.pth\"))\n",
    "model.eval()\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Load EEG data from EDF file\n",
    "edf_path = r\"C:/Users/obass/Desktop/linux_shared/v3.0.1/edf/eval/abnormal/01_tcp_ar/aaaaabdo_s003_t000.edf\"\n",
    "raw = mne.io.read_raw_edf(edf_path, preload=True)\n",
    "raw.pick_types(eeg=True)\n",
    "raw.filter(0.5, 40.)\n",
    "raw._data *= 1e6  # Convert signal to microvolts\n",
    "\n",
    "# Select a fixed set of EEG channels\n",
    "fixed_channels = [\n",
    "    'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF',\n",
    "    'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF',\n",
    "    'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF',\n",
    "    'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF',\n",
    "    'EEG A1-REF', 'EEG A2-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'\n",
    "]\n",
    "raw.pick_channels([ch for ch in fixed_channels if ch in raw.ch_names])\n",
    "\n",
    "# Warn if any expected channels are missing\n",
    "if len(raw.ch_names) < len(fixed_channels):\n",
    "    print(\"Warning: Some expected EEG channels are missing from the EDF file.\")\n",
    "\n",
    "# Create fixed-length non-overlapping windows from the EEG data\n",
    "X = raw.get_data()\n",
    "sampling_rate = 100\n",
    "window_size = 1000\n",
    "stride = 1000\n",
    "num_windows = (X.shape[1] - window_size) // stride\n",
    "\n",
    "X_windows = []\n",
    "for i in range(num_windows):\n",
    "    start = i * stride\n",
    "    end = start + window_size\n",
    "    win = X[:, start:end]\n",
    "    if win.shape[1] == window_size:\n",
    "        X_windows.append(torch.tensor(win, dtype=torch.float32))\n",
    "X_eval = torch.stack(X_windows)\n",
    "\n",
    "# Load names of selected features to extract\n",
    "with open(\"selected_feature_names.txt\", \"r\") as f:\n",
    "    selected_feature_names = set(line.strip() for line in f.readlines())\n",
    "\n",
    "# Determine which types of features are needed\n",
    "need_time = any(\"_time_\" in f for f in selected_feature_names)\n",
    "need_psd = any(\"_psd_\" in f for f in selected_feature_names)\n",
    "need_hjorth = any(\"_hjorth_\" in f for f in selected_feature_names)\n",
    "need_wavelet = any(\"_wavelet_\" in f for f in selected_feature_names)\n",
    "need_catch22 = any(\"_catch22_\" in f for f in selected_feature_names)\n",
    "\n",
    "feature_freq_bands = []\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(window):\n",
    "    features = []\n",
    "    for ch_idx, ch in enumerate(window):\n",
    "        ch = np.nan_to_num(ch, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if np.all(ch == ch[0]) or np.std(ch) < 1e-6:\n",
    "            features.extend([0.0 for name in selected_feature_names if name.startswith(f\"ch_{ch_idx}_\")])\n",
    "            continue\n",
    "        if need_time:\n",
    "            features += [\n",
    "                ch.mean() if f\"ch_{ch_idx}_time_mean\" in selected_feature_names else None,\n",
    "                ch.std() if f\"ch_{ch_idx}_time_std\" in selected_feature_names else None,\n",
    "                ch.max() if f\"ch_{ch_idx}_time_max\" in selected_feature_names else None,\n",
    "                ch.min() if f\"ch_{ch_idx}_time_min\" in selected_feature_names else None,\n",
    "                skew(ch) if f\"ch_{ch_idx}_time_skew\" in selected_feature_names else None,\n",
    "                kurtosis(ch) if f\"ch_{ch_idx}_time_kurtosis\" in selected_feature_names else None\n",
    "            ]\n",
    "        if need_psd:\n",
    "            freqs, psd = welch(ch, fs=sampling_rate, nperseg=256)\n",
    "            band_power = {\n",
    "                \"delta\": psd[(freqs >= 0.5) & (freqs < 4)].mean(),\n",
    "                \"theta\": psd[(freqs >= 4) & (freqs < 8)].mean(),\n",
    "                \"alpha\": psd[(freqs >= 8) & (freqs < 13)].mean(),\n",
    "                \"beta\": psd[(freqs >= 13) & (freqs < 30)].mean(),\n",
    "                \"gamma\": psd[(freqs >= 30) & (freqs < 40)].mean()\n",
    "            }\n",
    "            feature_freq_bands.append(band_power)\n",
    "            features += [\n",
    "                band_power['delta'] if f\"ch_{ch_idx}_psd_delta\" in selected_feature_names else None,\n",
    "                band_power['theta'] if f\"ch_{ch_idx}_psd_theta\" in selected_feature_names else None,\n",
    "                band_power['alpha'] if f\"ch_{ch_idx}_psd_alpha\" in selected_feature_names else None,\n",
    "                band_power['beta'] if f\"ch_{ch_idx}_psd_beta\" in selected_feature_names else None,\n",
    "                band_power['gamma'] if f\"ch_{ch_idx}_psd_gamma\" in selected_feature_names else None\n",
    "            ]\n",
    "        if need_hjorth:\n",
    "            d1, d2 = np.diff(ch), np.diff(np.diff(ch))\n",
    "            features += [\n",
    "                np.var(ch) if f\"ch_{ch_idx}_hjorth_var\" in selected_feature_names else None,\n",
    "                np.std(d1) / (np.std(ch) + 1e-8) if f\"ch_{ch_idx}_hjorth_mob\" in selected_feature_names else None,\n",
    "                np.std(d2) / (np.std(d1) + 1e-8) if f\"ch_{ch_idx}_hjorth_comp\" in selected_feature_names else None\n",
    "            ]\n",
    "        if need_wavelet:\n",
    "            coeffs = pywt.wavedec(ch, 'db4', level=3)\n",
    "            for i, c in enumerate(coeffs):\n",
    "                key = f\"ch_{ch_idx}_wavelet_cD{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.sqrt(np.sum(c ** 2)))\n",
    "        if need_catch22:\n",
    "            c22 = catch22_all(ch)[\"values\"]\n",
    "            for i, val in enumerate(c22):\n",
    "                key = f\"ch_{ch_idx}_catch22_{i}\"\n",
    "                if key in selected_feature_names:\n",
    "                    features.append(np.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0))\n",
    "    return np.array([f for f in features if f is not None], dtype=np.float32)\n",
    "\n",
    "# Extract features for each window\n",
    "X_feat = [extract_features(w.numpy()) for w in tqdm(X_eval, desc=\"Extracting features\")]\n",
    "X_feat = torch.tensor(np.stack(X_feat), dtype=torch.float32)\n",
    "\n",
    "# Normalize features using the pre-fitted scaler\n",
    "X_scaled = torch.tensor(scaler.transform(X_feat.numpy()), dtype=torch.float32)\n",
    "\n",
    "# Run model inference\n",
    "with torch.no_grad():\n",
    "    logits = model(X_scaled)\n",
    "    probs = softmax(logits, dim=1)\n",
    "    preds = probs.argmax(dim=1)\n",
    "    confidences = probs.max(dim=1).values\n",
    "\n",
    "# Identify windows classified as abnormal with high confidence\n",
    "abnormal_windows = (preds == 1) & (confidences > 0.9)\n",
    "abnormal_indices = torch.nonzero(abnormal_windows).cpu().numpy()\n",
    "if abnormal_indices.ndim == 0:\n",
    "    abnormal_indices = abnormal_indices.reshape(1)\n",
    "\n",
    "# Report number of abnormal windows detected\n",
    "print(\"Abnormal segments with confidence > 0.9:\", len(abnormal_indices))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
